{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Radu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:101: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 636 samples, validate on 208 samples\n",
      "Epoch 1/5\n",
      "636/636 [==============================] - 3s 5ms/step - loss: 1.3340 - mean_absolute_error: 0.8765 - val_loss: 3.3782 - val_mean_absolute_error: 1.4028\n",
      "Epoch 2/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 1.1533 - mean_absolute_error: 0.8110 - val_loss: 2.9249 - val_mean_absolute_error: 1.1349\n",
      "Epoch 3/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 1.1140 - mean_absolute_error: 0.7855 - val_loss: 5.2950 - val_mean_absolute_error: 1.8452\n",
      "Epoch 4/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 1.0265 - mean_absolute_error: 0.7562 - val_loss: 3.3697 - val_mean_absolute_error: 1.3366\n",
      "Epoch 5/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 0.9611 - mean_absolute_error: 0.7327 - val_loss: 2.8771 - val_mean_absolute_error: 1.1536\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "next\t14.798561\n",
      "Train on 636 samples, validate on 208 samples\n",
      "Epoch 1/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 25.4368 - mean_absolute_error: 2.9982 - val_loss: 4.4466 - val_mean_absolute_error: 1.7569\n",
      "Epoch 2/5\n",
      "636/636 [==============================] - 3s 4ms/step - loss: 21.5560 - mean_absolute_error: 2.8366 - val_loss: 6.3729 - val_mean_absolute_error: 2.2078\n",
      "Epoch 3/5\n",
      "636/636 [==============================] - 2s 3ms/step - loss: 19.2163 - mean_absolute_error: 2.5479 - val_loss: 4.3702 - val_mean_absolute_error: 1.7066\n",
      "Epoch 4/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 18.2132 - mean_absolute_error: 2.5159 - val_loss: 6.3986 - val_mean_absolute_error: 2.1890\n",
      "Epoch 5/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 17.3495 - mean_absolute_error: 2.4276 - val_loss: 11.8324 - val_mean_absolute_error: 3.1830\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "next\t15.861746\n",
      "Train on 636 samples, validate on 208 samples\n",
      "Epoch 1/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 6.1762 - mean_absolute_error: 1.9576 - val_loss: 26.5493 - val_mean_absolute_error: 4.4996\n",
      "Epoch 2/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 4.5467 - mean_absolute_error: 1.6990 - val_loss: 17.2337 - val_mean_absolute_error: 3.4619\n",
      "Epoch 3/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 4.1652 - mean_absolute_error: 1.5761 - val_loss: 13.7687 - val_mean_absolute_error: 2.9730\n",
      "Epoch 4/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 3.9221 - mean_absolute_error: 1.5384 - val_loss: 12.4278 - val_mean_absolute_error: 2.7460\n",
      "Epoch 5/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 3.8172 - mean_absolute_error: 1.4938 - val_loss: 12.2352 - val_mean_absolute_error: 2.5281\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "next\t47.62121\n",
      "Train on 158 samples, validate on 89 samples\n",
      "Epoch 1/5\n",
      "158/158 [==============================] - 1s 3ms/step - loss: 5.1241 - mean_absolute_error: 1.6423 - val_loss: 1.6749 - val_mean_absolute_error: 0.9718\n",
      "Epoch 2/5\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 4.5916 - mean_absolute_error: 1.5517 - val_loss: 1.6784 - val_mean_absolute_error: 1.0274\n",
      "Epoch 3/5\n",
      "158/158 [==============================] - 1s 4ms/step - loss: 3.3751 - mean_absolute_error: 1.3218 - val_loss: 1.9677 - val_mean_absolute_error: 1.0951\n",
      "Epoch 4/5\n",
      "158/158 [==============================] - 1s 4ms/step - loss: 3.1121 - mean_absolute_error: 1.3090 - val_loss: 2.2751 - val_mean_absolute_error: 1.1717\n",
      "Epoch 5/5\n",
      "158/158 [==============================] - 1s 4ms/step - loss: 2.7299 - mean_absolute_error: 1.1705 - val_loss: 2.3640 - val_mean_absolute_error: 1.2706\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "next\t7.960306\n",
      "Train on 432 samples, validate on 157 samples\n",
      "Epoch 1/5\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 64.4895 - mean_absolute_error: 5.7992 - val_loss: 211.8378 - val_mean_absolute_error: 12.4523\n",
      "Epoch 2/5\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 56.2882 - mean_absolute_error: 5.5554 - val_loss: 158.8876 - val_mean_absolute_error: 10.3785\n",
      "Epoch 3/5\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 48.5386 - mean_absolute_error: 5.0160 - val_loss: 191.6030 - val_mean_absolute_error: 11.6715\n",
      "Epoch 4/5\n",
      "432/432 [==============================] - 2s 4ms/step - loss: 41.7310 - mean_absolute_error: 4.5679 - val_loss: 134.4371 - val_mean_absolute_error: 9.0930\n",
      "Epoch 5/5\n",
      "432/432 [==============================] - 1s 3ms/step - loss: 38.3585 - mean_absolute_error: 4.3893 - val_loss: 163.0526 - val_mean_absolute_error: 10.7322\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "next\t73.95977\n",
      "Train on 636 samples, validate on 208 samples\n",
      "Epoch 1/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 1.5442 - mean_absolute_error: 1.0341 - val_loss: 7.5038 - val_mean_absolute_error: 2.3621\n",
      "Epoch 2/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 0.9961 - mean_absolute_error: 0.7650 - val_loss: 6.4923 - val_mean_absolute_error: 2.1845\n",
      "Epoch 3/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 0.8939 - mean_absolute_error: 0.6845 - val_loss: 4.5309 - val_mean_absolute_error: 1.7867\n",
      "Epoch 4/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 0.8099 - mean_absolute_error: 0.6424 - val_loss: 4.4637 - val_mean_absolute_error: 1.7747\n",
      "Epoch 5/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 0.7482 - mean_absolute_error: 0.6081 - val_loss: 3.8734 - val_mean_absolute_error: 1.6337\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "next\t18.32749\n",
      "Train on 636 samples, validate on 208 samples\n",
      "Epoch 1/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 11.6570 - mean_absolute_error: 2.3016 - val_loss: 11.1416 - val_mean_absolute_error: 2.6776\n",
      "Epoch 2/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 10.0277 - mean_absolute_error: 2.1214 - val_loss: 11.1930 - val_mean_absolute_error: 2.6506\n",
      "Epoch 3/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 9.7976 - mean_absolute_error: 2.1069 - val_loss: 11.8110 - val_mean_absolute_error: 2.7431\n",
      "Epoch 4/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 9.0188 - mean_absolute_error: 2.0549 - val_loss: 14.7346 - val_mean_absolute_error: 3.1623\n",
      "Epoch 5/5\n",
      "636/636 [==============================] - 2s 3ms/step - loss: 8.8521 - mean_absolute_error: 2.0465 - val_loss: 11.1187 - val_mean_absolute_error: 2.6447\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "next\t45.62997\n",
      "Train on 636 samples, validate on 208 samples\n",
      "Epoch 1/5\n",
      "636/636 [==============================] - 3s 4ms/step - loss: 25.2401 - mean_absolute_error: 3.2574 - val_loss: 2052.6122 - val_mean_absolute_error: 30.9000\n",
      "Epoch 2/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 23.1025 - mean_absolute_error: 3.0403 - val_loss: 1592.7229 - val_mean_absolute_error: 27.0392\n",
      "Epoch 3/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 20.3401 - mean_absolute_error: 2.9291 - val_loss: 1086.7441 - val_mean_absolute_error: 22.7335\n",
      "Epoch 4/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 20.0423 - mean_absolute_error: 2.7780 - val_loss: 1199.1796 - val_mean_absolute_error: 24.4865\n",
      "Epoch 5/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 17.3604 - mean_absolute_error: 2.6334 - val_loss: 1048.6378 - val_mean_absolute_error: 22.7483\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "next\t186.87949\n",
      "Train on 636 samples, validate on 208 samples\n",
      "Epoch 1/5\n",
      "636/636 [==============================] - 3s 4ms/step - loss: 0.5610 - mean_absolute_error: 0.5748 - val_loss: 0.1679 - val_mean_absolute_error: 0.3299\n",
      "Epoch 2/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 0.5467 - mean_absolute_error: 0.5686 - val_loss: 0.1676 - val_mean_absolute_error: 0.3341\n",
      "Epoch 3/5\n",
      "636/636 [==============================] - 3s 4ms/step - loss: 0.5309 - mean_absolute_error: 0.5592 - val_loss: 0.1614 - val_mean_absolute_error: 0.3241\n",
      "Epoch 4/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 0.5231 - mean_absolute_error: 0.5536 - val_loss: 0.1648 - val_mean_absolute_error: 0.3312\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 2s 4ms/step - loss: 0.5110 - mean_absolute_error: 0.5469 - val_loss: 0.1731 - val_mean_absolute_error: 0.3410\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "next\t1.1516724\n",
      "Train on 506 samples, validate on 176 samples\n",
      "Epoch 1/5\n",
      "506/506 [==============================] - 2s 4ms/step - loss: 12.0608 - mean_absolute_error: 2.5135 - val_loss: 0.7130 - val_mean_absolute_error: 0.5853\n",
      "Epoch 2/5\n",
      "506/506 [==============================] - 2s 4ms/step - loss: 10.4533 - mean_absolute_error: 2.3201 - val_loss: 0.8500 - val_mean_absolute_error: 0.7721\n",
      "Epoch 3/5\n",
      "506/506 [==============================] - 2s 4ms/step - loss: 10.0473 - mean_absolute_error: 2.3056 - val_loss: 0.7191 - val_mean_absolute_error: 0.7075\n",
      "Epoch 4/5\n",
      "506/506 [==============================] - 2s 4ms/step - loss: 8.5597 - mean_absolute_error: 2.1131 - val_loss: 0.5645 - val_mean_absolute_error: 0.5292\n",
      "Epoch 5/5\n",
      "506/506 [==============================] - 2s 4ms/step - loss: 8.7650 - mean_absolute_error: 2.1178 - val_loss: 0.9112 - val_mean_absolute_error: 0.8144\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "next\t3.3653078\n",
      "Train on 636 samples, validate on 208 samples\n",
      "Epoch 1/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 9.0386 - mean_absolute_error: 1.9371 - val_loss: 39.4237 - val_mean_absolute_error: 5.1757\n",
      "Epoch 2/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 8.7996 - mean_absolute_error: 1.8620 - val_loss: 42.2470 - val_mean_absolute_error: 5.0549\n",
      "Epoch 3/5\n",
      "636/636 [==============================] - 2s 3ms/step - loss: 8.4456 - mean_absolute_error: 1.7675 - val_loss: 44.3302 - val_mean_absolute_error: 5.6584\n",
      "Epoch 4/5\n",
      "636/636 [==============================] - 3s 4ms/step - loss: 8.7588 - mean_absolute_error: 1.9327 - val_loss: 45.8253 - val_mean_absolute_error: 5.6361\n",
      "Epoch 5/5\n",
      "636/636 [==============================] - 2s 4ms/step - loss: 6.8866 - mean_absolute_error: 1.6869 - val_loss: 40.7282 - val_mean_absolute_error: 5.3989\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "next\t29.112322\n",
      "Train on 446 samples, validate on 161 samples\n",
      "Epoch 1/5\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 11.4165 - mean_absolute_error: 2.1444 - val_loss: 33.3742 - val_mean_absolute_error: 4.4474\n",
      "Epoch 2/5\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 10.2819 - mean_absolute_error: 2.0263 - val_loss: 30.2071 - val_mean_absolute_error: 4.2315\n",
      "Epoch 3/5\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 10.0854 - mean_absolute_error: 2.0177 - val_loss: 32.1149 - val_mean_absolute_error: 4.3454\n",
      "Epoch 4/5\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 9.6869 - mean_absolute_error: 1.9843 - val_loss: 24.9727 - val_mean_absolute_error: 3.8304\n",
      "Epoch 5/5\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 9.8745 - mean_absolute_error: 2.0890 - val_loss: 51.1998 - val_mean_absolute_error: 5.6543\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "next\t33.561302\n",
      "Train on 124 samples, validate on 81 samples\n",
      "Epoch 1/5\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 1.2903 - mean_absolute_error: 0.7498 - val_loss: 0.2367 - val_mean_absolute_error: 0.3815\n",
      "Epoch 2/5\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 0.4115 - mean_absolute_error: 0.4325 - val_loss: 0.2415 - val_mean_absolute_error: 0.3868\n",
      "Epoch 3/5\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2994 - mean_absolute_error: 0.3891 - val_loss: 0.2219 - val_mean_absolute_error: 0.3652\n",
      "Epoch 4/5\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.2073 - mean_absolute_error: 0.3313 - val_loss: 0.2117 - val_mean_absolute_error: 0.3531\n",
      "Epoch 5/5\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 0.1756 - mean_absolute_error: 0.3065 - val_loss: 0.2077 - val_mean_absolute_error: 0.3485\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "next\t1.9130645\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from alpha_vantage.techindicators import TechIndicators\n",
    "from alpha_vantage.sectorperformance import SectorPerformances\n",
    "from alpha_vantage.cryptocurrencies import CryptoCurrencies\n",
    "import json\n",
    "import http\n",
    "\n",
    "def companies_list():\n",
    "    symb=[]\n",
    "    with open('nasdaq-company-list.csv', newline='') as csvfile:\n",
    "        reader=csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            symb.append(row['Symbol'])\n",
    "        symb.append('MSFT')\n",
    "        symb.append('APPL')\n",
    "        symb.append('fb')\n",
    "        symb.append('nflx')\n",
    "        symb.append('fvrr')\n",
    "        symb.append('sbux')\n",
    "        symb.append('mcb')\n",
    "        symb.append('m')\n",
    "        symb.append('kirk')\n",
    "        symb.append('rdsa')\n",
    "        symb.append('tsla')\n",
    "        return symb[:20]\n",
    "    \n",
    "\n",
    "def get_timeseries(symbol):\n",
    "    conec = http.client.HTTPSConnection('www.alphavantage.co', timeout = 10)\n",
    "    conec.request(\"GET\", '/query?function=TIME_SERIES_WEEKLY&symbol='+symbol+'&interval=5min&apikey=07THEOFGYUDV073A')\n",
    "    resp=conec.getresponse()\n",
    "    return json.loads(resp.read().decode('utf8'))\n",
    "\n",
    "#for trainning\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import keras\n",
    "import csv\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Convolution1D, Flatten, MaxPooling1D\n",
    "import datetime as dt\n",
    "import time \n",
    "import urllib.request, json\n",
    "import os\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from alphavantage import time_series_weekly\n",
    "\n",
    "# variables: '1. open', '2. high', '3. low', '4. close'\n",
    "# Make plots bigger\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "\n",
    "close=[]\n",
    "test=[]\n",
    "low=[]\n",
    "high=[]\n",
    "    #print(timestamp) -> from 2019 to begining\n",
    "    #]\\\\print(test)\n",
    "\n",
    "def make_timeseries_regressor(window_size, filter_length, nb_input_series=1, nb_outputs=1, nb_filter=4):\n",
    "    model = Sequential((\n",
    "        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu', input_shape=(window_size, nb_input_series)),\n",
    "        MaxPooling1D(),\n",
    "        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu'),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dense(nb_outputs, activation='linear'),\n",
    "    ))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_timeseries_instances(timeseries, window_size):\n",
    "    timeseries = np.asarray(timeseries)\n",
    "    assert 0 < window_size < timeseries.shape[0]\n",
    "    X = np.atleast_3d(np.array([timeseries[start:start + window_size] for start in range(0, timeseries.shape[0] - window_size)]))\n",
    "    y = timeseries[window_size:]\n",
    "    q = np.atleast_3d([timeseries[-window_size:]])\n",
    "    return X, y, q\n",
    "\n",
    "\n",
    "def evaluate_timeseries(model, timeseries, window_size):\n",
    "    filter_length = 5\n",
    "    nb_filter = 4\n",
    "    timeseries = np.atleast_2d(timeseries)\n",
    "    if timeseries.shape[0] == 1:\n",
    "        timeseries = timeseries.T       #1D vectors -> 2D column vectors\n",
    "\n",
    "    nb_samples, nb_series = timeseries.shape\n",
    "   # model = make_timeseries_regressor(window_size=window_size, filter_length=filter_length, nb_input_series=nb_series, nb_outputs=nb_series, nb_filter=nb_filter)\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    X, y, q = make_timeseries_instances(timeseries, window_size)\n",
    "    test_size = int(0.2 * nb_samples)\n",
    "    X_train, X_test, y_train, y_test = X[:-test_size], X[-test_size:], y[:-test_size], y[-test_size:]\n",
    "    model.fit(X_train, y_train, nb_epoch=5, batch_size=2, validation_data=(X_test, y_test))\n",
    "\n",
    "    print(type(model))\n",
    "    pred = model.predict(X_test)\n",
    "   # print('\\n\\nactual', 'predicted', sep='\\t')\n",
    "    #for actual, predicted in zip(y_test, pred.squeeze()):\n",
    "     #   print(actual.squeeze(), predicted, sep='\\t')\n",
    "    print('next', model.predict(q).squeeze(), sep='\\t')\n",
    "    return model.predict(q)\n",
    "\n",
    "\n",
    "#def company()\n",
    "def load_json():\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model=model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(\"model.h5\")\n",
    "    return loaded_model\n",
    "\n",
    "def predict(loaded_model, symbol):\n",
    "    print(symbol)\n",
    "    t=time_series_weekly(symbol)\n",
    "    inTimeseries = []\n",
    "    for timestamp, data in t.items():\n",
    "        clos=float(data['4. close'])\n",
    "        inTimeseries.insert(0, clos)\n",
    "   # print(inTimeseries)\n",
    "    return loaded_model.predict(np.atleast_3d(inTimeseries))\n",
    "#company_list=pd.read_csv(\"nasdaq-company-list.csv\")\n",
    "#print(company_list)\n",
    "\n",
    "    \n",
    "def main():\n",
    "    \"\"\"Prepare input data, build model, evaluate.\"\"\"\n",
    "    np.set_printoptions(threshold=25)\n",
    "    companies=companies_list()\n",
    "    window_size = 200\n",
    "    training_threshold = window_size * 2\n",
    "    json_file = open('model.json', 'r')\n",
    "    model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model=model_from_json(model_json)\n",
    "    model.load_weights(\"model.h5\")\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "    #model = make_timeseries_regressor(window_size, 4, nb_input_series=1, nb_outputs=1, nb_filter=4)\n",
    "    \n",
    "    for symbol in companies:\n",
    "        jro = None\n",
    "        try:\n",
    "            jro = time_series_weekly(symbol)\n",
    "        except:\n",
    "            continue\n",
    "        ts_length = len(jro.items())\n",
    "        if ts_length < training_threshold:\n",
    "            continue\n",
    "        inTimeseries = []\n",
    "        for timestamp, data in jro.items():\n",
    "            clos=float(data['4. close'])\n",
    "            inTimeseries.insert(0, clos)\n",
    "        filter_length=4\n",
    "        evaluate_timeseries(model, inTimeseries, window_size)\n",
    "        time.sleep(15)\n",
    "    modelJson = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(modelJson)\n",
    "    model.save_weights(\"model.h5\")\n",
    "\n",
    "    print('a')\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts = TimeSeries(key='07THEOFGYUDV073A', output_format='pandas')\n",
    "\n",
    "window_size=100\n",
    "N=training_data.size\n",
    "avg_predictions=[]\n",
    "avg_x=[]\n",
    "for pred_idx in range(window_size,N):\n",
    "\n",
    "    if pred_idx >= N:\n",
    "        date = jro.datetime.strptime(k, '%Y-%m-%d').date() + dt.timedelta(days=1)\n",
    "    else:\n",
    "        date = jro.loc[pred_idx,'']\n",
    "\n",
    "    avg_predictions.append(np.mean(train_data[pred_idx-window_size:pred_idx]))\n",
    "    mse_errors.append((avg_predictions[-1]-training_data[pred_idx])**2)\n",
    "    std_avg_x.append(date)\n",
    "\n",
    "print('MSE predic %.5f'%(0.5*np.mean(mse_errors)))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "print(\"Close value\")\n",
    "    print('\\nSimple single timeseries vector prediction')\n",
    "                # The timeseries f(t) = t\n",
    "    evaluate_timeseries(mid, window_size)\n",
    "\n",
    "    print('\\nMultiple-input, multiple-output prediction')\n",
    "    timeseries = np.array([np.arange(ts_length), -np.arange(ts_length)]).T      # The timeseries f(t) = [t, -t]\n",
    "    evaluate_timeseries(mid, window_size)\n",
    "    \n",
    "    print(\"Low value\")\n",
    "    print('\\nSimple single timeseries vector prediction')\n",
    "    timeseries = np.arange(ts_length)                   # The timeseries f(t) = t\n",
    "    evaluate_timeseries(low, window_size)\n",
    "\n",
    "    print('\\nMultiple-input, multiple-output prediction')\n",
    "    timeseries = np.array([np.arange(ts_length), -np.arange(ts_length)]).T      # The timeseries f(t) = [t, -t]\n",
    "    evaluate_timeseries(low, window_size)\n",
    "    \n",
    "    print(\"High Value\")\n",
    "    print('\\nSimple single timeseries vector prediction')\n",
    "    timeseries = np.arange(ts_length)                   # The timeseries f(t) = t\n",
    "    evaluate_timeseries(high, window_size)\n",
    "\n",
    "    print('\\nMultiple-input, multiple-output prediction')\n",
    "    timeseries = np.array([np.arange(ts_length), -np.arange(ts_length)]).T      # The timeseries f(t) = [t, -t]\n",
    "    evaluate_timeseries(high, window_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EMA = 0.0\n",
    "#gamma = 0.1\n",
    "#for ti in range(11000):\n",
    " # EMA = gamma*train_reshape[ti] + (1-gamma)*EMA\n",
    "  #train_reshape[ti] = EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
