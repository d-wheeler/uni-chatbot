{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from alpha_vantage.techindicators import TechIndicators\n",
    "from alpha_vantage.sectorperformance import SectorPerformances\n",
    "from alpha_vantage.cryptocurrencies import CryptoCurrencies\n",
    "import json\n",
    "import http\n",
    "\n",
    "def companies_list():\n",
    "    symb=[]\n",
    "    with open('nasdaq-company-list.csv', newline='') as csvfile:\n",
    "        reader=csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            symb.append(row['Symbol'])\n",
    "        return symb[:101]\n",
    "    \n",
    "\n",
    "def get_timeseries(symbol):\n",
    "    conec = http.client.HTTPSConnection('www.alphavantage.co', timeout = 10)\n",
    "    conec.request(\"GET\", '/query?function=TIME_SERIES_WEEKLY&symbol='+symbol+'&interval=5min&apikey=07THEOFGYUDV073A')\n",
    "    resp=conec.getresponse()\n",
    "    return json.loads(resp.read().decode('utf8'))\n",
    "\n",
    "#for trainning\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import keras\n",
    "import csv\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Convolution1D, Flatten, MaxPooling1D\n",
    "import datetime as dt\n",
    "import urllib.request, json\n",
    "import os\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from alphavantage import time_series_weekly\n",
    "\n",
    "# variables: '1. open', '2. high', '3. low', '4. close'\n",
    "# Make plots bigger\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "\n",
    "close=[]\n",
    "test=[]\n",
    "low=[]\n",
    "high=[]\n",
    "for timestamp, data in jro['Weekly Time Series'].items():\n",
    "    highs = float(data['2. high'])\n",
    "    lows = float(data['3. low'])\n",
    "    clos=float(data['4. close'])\n",
    "    close.insert(0, clos)\n",
    "    low.insert(0, lows)\n",
    "    high.insert(0, highs)\n",
    "    #print(timestamp) -> from 2019 to begining\n",
    "    #]\\\\print(test)\n",
    "\n",
    "def make_timeseries_regressor(window_size, filter_length, nb_input_series=1, nb_outputs=1, nb_filter=4):\n",
    "    model = Sequential((\n",
    "        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu', input_shape=(window_size, nb_input_series)),\n",
    "        MaxPooling1D(),\n",
    "        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu'),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dense(nb_outputs, activation='linear'),\n",
    "    ))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_timeseries_instances(timeseries, window_size):\n",
    "    timeseries = np.asarray(timeseries)\n",
    "    assert 0 < window_size < timeseries.shape[0]\n",
    "    X = np.atleast_3d(np.array([timeseries[start:start + window_size] for start in range(0, timeseries.shape[0] - window_size)]))\n",
    "    y = timeseries[window_size:]\n",
    "    q = np.atleast_3d([timeseries[-window_size:]])\n",
    "    return X, y, q\n",
    "\n",
    "\n",
    "def evaluate_timeseries(timeseries, window_size):\n",
    "    filter_length = 5\n",
    "    nb_filter = 4\n",
    "    timeseries = np.atleast_2d(timeseries)\n",
    "    if timeseries.shape[0] == 1:\n",
    "        timeseries = timeseries.T       #1D vectors -> 2D column vectors\n",
    "\n",
    "    nb_samples, nb_series = timeseries.shape\n",
    "   # model = make_timeseries_regressor(window_size=window_size, filter_length=filter_length, nb_input_series=nb_series, nb_outputs=nb_series, nb_filter=nb_filter)\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    X, y, q = make_timeseries_instances(timeseries, window_size)\n",
    "    test_size = int(0.2 * nb_samples)\n",
    "    X_train, X_test, y_train, y_test = X[:-test_size], X[-test_size:], y[:-test_size], y[-test_size:]\n",
    "    model.fit(X_train, y_train, nb_epoch=1, batch_size=2, validation_data=(X_test, y_test))\n",
    "\n",
    "    print(type(model))\n",
    "    pred = model.predict(X_test)\n",
    "   # print('\\n\\nactual', 'predicted', sep='\\t')\n",
    "    #for actual, predicted in zip(y_test, pred.squeeze()):\n",
    "     #   print(actual.squeeze(), predicted, sep='\\t')\n",
    "    print('next', model.predict(q).squeeze(), sep='\\t')\n",
    "    return model.predict(q)\n",
    "\n",
    "\n",
    "#def company()\n",
    "def load_json():\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model=model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(\"model.h5\")\n",
    "    return loaded_model\n",
    "\n",
    "def predict(loaded_model, symbol):\n",
    "    t=time_series_weekly(symbol)\n",
    "    inTimeseries = []\n",
    "    for timestamp, data in t.items():\n",
    "        clos=float(data['4. close'])\n",
    "        inTimeseries.insert(0, clos)\n",
    "    print(inTimeseries)\n",
    "    return loaded_model.predict(np.atleast_3d(inTimeseries))\n",
    "#company_list=pd.read_csv(\"nasdaq-company-list.csv\")\n",
    "#print(company_list)\n",
    "\n",
    "    \n",
    "def main():\n",
    "    \"\"\"Prepare input data, build model, evaluate.\"\"\"\n",
    "    np.set_printoptions(threshold=25)\n",
    "    companies=companies_list()\n",
    "    model = make_timeseries_regressor(1043, 4, nb_input_series=1, nb_outputs=1, nb_filter=4)\n",
    "    for symbol in companies:\n",
    "        jro = get_timeseries(symbol)\n",
    "        #ts_length = len(jro['Weekly Time Series'].items())\n",
    "        #window_size = int(0.2*(ts_length))\n",
    "        #timeseries = np.arange(ts_length)\n",
    "        filter_length=4\n",
    "        print(predict(model, symbol))\n",
    "    modelJson = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(modelJson)\n",
    "    model.save_weights(\"model.h5\")\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model=model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(\"model.h5\")\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts = TimeSeries(key='07THEOFGYUDV073A', output_format='pandas')\n",
    "\n",
    "window_size=100\n",
    "N=training_data.size\n",
    "avg_predictions=[]\n",
    "avg_x=[]\n",
    "for pred_idx in range(window_size,N):\n",
    "\n",
    "    if pred_idx >= N:\n",
    "        date = jro.datetime.strptime(k, '%Y-%m-%d').date() + dt.timedelta(days=1)\n",
    "    else:\n",
    "        date = jro.loc[pred_idx,'']\n",
    "\n",
    "    avg_predictions.append(np.mean(train_data[pred_idx-window_size:pred_idx]))\n",
    "    mse_errors.append((avg_predictions[-1]-training_data[pred_idx])**2)\n",
    "    std_avg_x.append(date)\n",
    "\n",
    "print('MSE predic %.5f'%(0.5*np.mean(mse_errors)))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "print(\"Close value\")\n",
    "    print('\\nSimple single timeseries vector prediction')\n",
    "                # The timeseries f(t) = t\n",
    "    evaluate_timeseries(mid, window_size)\n",
    "\n",
    "    print('\\nMultiple-input, multiple-output prediction')\n",
    "    timeseries = np.array([np.arange(ts_length), -np.arange(ts_length)]).T      # The timeseries f(t) = [t, -t]\n",
    "    evaluate_timeseries(mid, window_size)\n",
    "    \n",
    "    print(\"Low value\")\n",
    "    print('\\nSimple single timeseries vector prediction')\n",
    "    timeseries = np.arange(ts_length)                   # The timeseries f(t) = t\n",
    "    evaluate_timeseries(low, window_size)\n",
    "\n",
    "    print('\\nMultiple-input, multiple-output prediction')\n",
    "    timeseries = np.array([np.arange(ts_length), -np.arange(ts_length)]).T      # The timeseries f(t) = [t, -t]\n",
    "    evaluate_timeseries(low, window_size)\n",
    "    \n",
    "    print(\"High Value\")\n",
    "    print('\\nSimple single timeseries vector prediction')\n",
    "    timeseries = np.arange(ts_length)                   # The timeseries f(t) = t\n",
    "    evaluate_timeseries(high, window_size)\n",
    "\n",
    "    print('\\nMultiple-input, multiple-output prediction')\n",
    "    timeseries = np.array([np.arange(ts_length), -np.arange(ts_length)]).T      # The timeseries f(t) = [t, -t]\n",
    "    evaluate_timeseries(high, window_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EMA = 0.0\n",
    "#gamma = 0.1\n",
    "#for ti in range(11000):\n",
    " # EMA = gamma*train_reshape[ti] + (1-gamma)*EMA\n",
    "  #train_reshape[ti] = EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
